{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.preprocessing import RollingFeatures\n",
    "from skforecast.recursive import ForecasterRecursiveMultiSeries\n",
    "from skforecast.model_selection import (\n",
    "    TimeSeriesFold,\n",
    "    bayesian_search_forecaster_multiseries,\n",
    "    backtesting_forecaster_multiseries,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from src.data import load_training_data, make_exog_features, split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train.shape=(396, 58)\n",
      "data_test.shape=(366, 58)\n",
      "Train dates : 2022-10-01 00:00:00 --- 2023-10-31 00:00:00   (n=396)\n",
      "Test dates  : 2023-11-01 00:00:00 --- 2024-10-31 00:00:00   (n=366)\n"
     ]
    }
   ],
   "source": [
    "data = load_training_data()\n",
    "data = make_exog_features(data)\n",
    "# Encoding exog features as categorical for training\n",
    "data = data.astype({col: \"category\" for col in data.filter(like=\"exog_\").columns})\n",
    "data_train, data_test = split_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aa87cec361439eaf85d77cab8c9e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182] \n",
      "  Parameters: {'num_leaves': 37, 'feature_fraction': 0.9800975145540853, 'bagging_fraction': 0.6868697806837848, 'min_child_samples': 6}\n",
      "  Backtesting metric: 11586.069437461136\n",
      "  Levels: ['ba_AECI', 'ba_AVA', 'ba_AZPS', 'ba_BANC', 'ba_BPAT', 'ba_CHPD', 'ba_CISO', 'ba_CPLE', 'ba_CPLW', 'ba_DOPD', 'ba_DUK', 'ba_EPE', 'ba_ERCO', 'ba_FMPP', 'ba_FPC', 'ba_FPL', 'ba_GCPD', 'ba_GVL', 'ba_HST', 'ba_IID', 'ba_IPCO', 'ba_ISNE', 'ba_JEA', 'ba_LDWP', 'ba_LGEE', 'ba_MISO', 'ba_NEVP', 'ba_NWMT', 'ba_NYIS', 'ba_PACE', 'ba_PACW', 'ba_PGE', 'ba_PJM', 'ba_PNM', 'ba_PSCO', 'ba_PSEI', 'ba_SC', 'ba_SCEG', 'ba_SCL', 'ba_SEC', 'ba_SOCO', 'ba_SPA', 'ba_SRP', 'ba_SWPP', 'ba_TAL', 'ba_TEC', 'ba_TEPC', 'ba_TIDC', 'ba_TPWR', 'ba_TVA', 'ba_WACM', 'ba_WALC', 'ba_WAUW']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting up forecaster\n",
    "forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor=LGBMRegressor(\n",
    "        random_state=123,\n",
    "        verbose=-1,\n",
    "        categorical_feaure=data_train.filter(like=\"exog_\").columns.tolist(),\n",
    "    ),\n",
    "    lags = 7, # Placeholder, the value will be overwritten\n",
    "    window_features=RollingFeatures(\n",
    "        stats=[\"mean\", \"mean\", \"mean\", \"mean\", \"std\", \"std\", \"std\", \"std\"],\n",
    "        window_sizes=[7, 30, 182, 365, 7, 30, 182, 365],\n",
    "    ),  # Rolling means and stds for 1w, 1m, 6m, 12m\n",
    "    encoding=\"ordinal\",\n",
    "    transformer_series=StandardScaler(),  # Transforms each target series using standard scaler. Tranformations are applied under the hood when predicting and the prediction itself is returned on the original scale.\n",
    "    transformer_exog=StandardScaler(),\n",
    ")\n",
    "\n",
    "\n",
    "# Search space\n",
    "def search_space(trial):\n",
    "    return {\n",
    "        \"lags\": trial.suggest_categorical(\"lags\", [1, 7, 30, 182]),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 1.0\n",
    "        ), \n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 1.0),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 3, 100),\n",
    "    }\n",
    "\n",
    "cv = TimeSeriesFold(\n",
    "    steps=1,\n",
    "    initial_train_size=len(data_train),\n",
    "    refit=False,\n",
    "    fixed_train_size=True,\n",
    "    allow_incomplete_fold=True,\n",
    ")\n",
    "\n",
    "results, best_trial = bayesian_search_forecaster_multiseries(\n",
    "    forecaster=forecaster,\n",
    "    series=data.filter(like=\"ba_\"),\n",
    "    exog=data.filter(like=\"exog_\"),\n",
    "    search_space=search_space,\n",
    "    cv=cv,\n",
    "    metric=\"mean_absolute_error\",\n",
    "    aggregate_metric=\"average\",\n",
    "    n_trials=200, \n",
    "    random_state=123,\n",
    "    n_jobs=\"auto\",\n",
    "    verbose=False,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = best_trial.params\n",
    "\n",
    "best_lags = best_params.pop(\"lags\")\n",
    "\n",
    "tuned_forecaster = ForecasterRecursiveMultiSeries(\n",
    "    regressor=LGBMRegressor(\n",
    "        random_state=123,\n",
    "        verbose=-1,\n",
    "        categorical_feaure=data_train.filter(like=\"exog_\").columns.tolist(),\n",
    "        **best_params,\n",
    "    ),\n",
    "    lags=best_lags,\n",
    "    window_features=RollingFeatures(\n",
    "        stats=[\"mean\", \"mean\", \"mean\", \"mean\", \"std\", \"std\", \"std\", \"std\"],\n",
    "        window_sizes=[7, 30, 182, 365, 7, 30, 182, 365],\n",
    "    ),\n",
    "    encoding=\"ordinal\",\n",
    "    transformer_series=StandardScaler(),\n",
    "    transformer_exog=StandardScaler(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/douglaslazenby/Documents/Projects/energy-demand-forecasting/.venv/lib/python3.11/site-packages/skforecast/model_selection/_validation.py:638: LongTrainingWarning: The forecaster will be fit 366 times. This can take substantial amounts of time. If not feasible, try with `refit = False`.\n",
      " \n",
      " You can suppress this warning using: warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdcf4f8788742e68de2a4d89ac393db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = TimeSeriesFold(\n",
    "    steps=1,\n",
    "    initial_train_size=len(data_train),\n",
    "    refit=True,\n",
    "    fixed_train_size=True,\n",
    "    allow_incomplete_fold=True,\n",
    ")\n",
    "\n",
    "metrics, backtest_predictions = backtesting_forecaster_multiseries(\n",
    "    forecaster=tuned_forecaster,\n",
    "    series=data.filter(like=\"ba_\"),\n",
    "    exog=data.filter(like=\"exog_\"),\n",
    "    cv=cv,\n",
    "    levels=None,\n",
    "    metric=\"mean_absolute_error\",\n",
    "    add_aggregated_metric=True,\n",
    "    n_jobs=\"auto\",\n",
    "    verbose=False,\n",
    "    show_progress=True,\n",
    "    suppress_warnings=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>levels</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>average</td>\n",
       "      <td>7877.053637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     levels  mean_absolute_error\n",
       "53  average          7877.053637"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics[metrics[\"levels\"] == \"average\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
